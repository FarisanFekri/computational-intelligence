# Computational-Intelligence
Personal repository for computational intelligence 2023-2024

**10/04/2023**
-
- Tried to the virtual environment locally in my pc.

**10/12/2023**
- 
- Trying different queues during the cancelled class of the following date.

**10/25/2023**
-
- Created and set up the personal repository for the computational intellignece 2023/2024
- Looked at some codes of my colleagues repositories and how they have done the set covering.
- Started doing some heuristic for the first lab.

**10/26/2023**
-
- Thought a seemingly optimisitc way with the help of my colleagues
- Finished the first lab.
- Pushed the lab to the repoitory

**10/27/2023**
-
- Place the repository link in the google document professor has provided.

**11/03/2023**
-
- Understanding how the halloween challenged works by with a collegue

**11/06/2023**
-
- Trying to figure out lab 2's agginment
- Playing the nim sum game and figuring out how does it work

**11/11/2023**
- 
- Try to understand deeper the theories which might be needed for lab 2 
- Working on a solution for lab 2 

**11/13/2023**
-
- Figuring out an optimal solution for lab 2
- Coding the population and fitness with a few of my collegues 

**11/14/2023**
-
- Finalization of lab 2 as we got to a perfect score

**11/17/2023**
--
- Committing lab 2 to the github repository
- Updating the log

**11/22/2023**
-- 
- Studying theory necessities for Lab 9 with some collegues 

**11/23/2023**
--
- Writing Some peer reviews of Lab 2 for two of my collegues 
- Asking some of my collegues to write a peer review of Lab 2 for me if they have the time

**11/24/2023**
--
- Implementing the basics of the Lab 9 with some collegues without major tests

**11/27/2023**
--
- Testing the Lab 9 implemnetation and tried to reduce the number of calls to the fitness by reducing the number of generations/offspring size only to ES with collegues

**11/28/2023**
--
- Searching and understanding out the classic genetic algorithm used for AI learning to play Google Chrome Dinosaur Game.
Each generation contains 500 individuals, the individuals which do the best live on to mutate for the next generations until you have an optimal solution which in this case is a dinosaur which can do a big jump, small jump and duck perfectly. In other words, we have a dinosaur which can't die.
The genotype in this scenario would represent the set of parameters or weights that define the neural network controlling the behavior of the dinosaur. If you use a neural network to control the dinosaur's actions (like jumping or ducking), the genotype would consist of the weights and biases of the neural network connections.
The phenotype, in this case, is the actual behavior of the dinosaur in the game as a result of applying the neural network specified by its genotype. It represents how well the dinosaur is able to play the game.
The phenotype is evaluated based on the performance of the dinosaur, such as how far it runs, how many obstacles it avoids, and how long it survives. The fitness function would quantify these aspects of performance.
    Initialization:
        In the first generation, you randomly generate 500 individuals, each with its own set of neural network weights (genotype).

    Evaluation:
        Each individual's phenotype is determined by letting the corresponding neural network control the dinosaur in the game. The performance of each dinosaur is measured using a fitness function, which could be based on factors like the distance covered, obstacles avoided, and survival time.

    Selection:
        The top-performing individuals (those with the best phenotypes) are selected to pass their genotypes to the next generation. This could be, for example, the top 10% of individuals.

    Crossover and Mutation:
        Crossover and mutation operations are applied to the genotypes of the selected individuals to create the next generation. Crossover involves combining the genetic information of two parents, and mutation introduces small random changes to the genotypes.

    Repeat:
        The process is repeated for multiple generations. Over time, the genotypes are fine-tuned through the selection, crossover, and mutation operations, leading to the evolution of a neural network that performs well in the game.

The goal is to evolve a genotype (set of neural network weights) that produces a phenotype (dinosaur behavior) that excels in playing the Google Chrome Dinosaur Game, gradually improving over generations until a highly effective strategy is discovered

**12/03/2023**
--
- Finalizing the Lab 9 implementation and pushing it on the github repository

**12/07/2023**
--
- Attending the lecture to understand the project of the course and later on discussing it with some collegues and what is necessary to be done regarding the project
- Studying the theory about Promoting Diversity for the rest of the days with collegues and catching up with essential topics

**12/10/2023**
--
- Writing some peer reviews of Lab 9 for three of my collegues 
- Asking some of my collegues to write a peer review of Lab 9 for me if they have the time

**12/14/2023**
--
- Study the theory regarding Adversarial Search and Reinforcement Learning slides with some collegues from morning until before the class starts

**12/15/2023**
--
- Reviewing the theory relating to Reinforcement Learning 
- Discussing the solution of the porfessor regarding the Lab 10

**12/18/2023**
--
- Meeting online with the usual collegues to study the slides if Reinforcement Learning and finishing it
- Discussing a little more about the Lab 10 and deciding on how to expand it
The ideas for now are: 
1) adding action-value function
2) adding Hybdrid Montecarlo simulation with full game simulation

**12/20/2023**
--
- Implementing the discussed ideas previously with collegues on an online meeting call for Lab 10 and acheiving good results on the same day

**12/22/2023**
-- 
- Continuing with the Theory, closing the Knowledge-based agent alongside with Multi-agent systems and Swarm Intelligence with the contribution of my collegues on an online call, discussing the matters accordingly together while reviewing the subjects

**12/24/2023**
--
- Adding the results of the tests running and some comments for Lab 10 as the finishing touches

**12/25/2023**
--
- Lab 10 Commit
- Updating the log 

